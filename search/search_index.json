{
    "docs": [
        {
            "location": "/",
            "text": "Zenroom - DECODE project\n\n\n\n\n\n\nRestricted execution environment\n for cryptographic operations in a \nTuring-incomplete language\n based on LUA syntax and coarse-grained control of number of operations and memory used.\n\n\nZenroom follows a minimal design with security and portability in mind: it can be used in \nuntrusted distributed computing\n, for instance in distributed ledger or \nblockchain smart contracts\n.\n\n\nZenroom compiles to fully static native binaries for embedded use, but also to javascript or webassembly modules for client-side use for instance in mobile applications.\n\n\nWith Zenroom is easy to write portable software using end-to-end client-side encryption using various classic and advanced cryptographic primitives to manage asymmetric keys, key derivation, hashing and signing functionalities.\n\n\nThis README documentation is operational. For more information on the purpose and design of this software see:\n\n\n\n\nThe DECODE Project website: https://decodeproject.eu\n\n\nThe Zenroom whitepaper and API documentation: https://decodeproject.github.io/zenroom\n\n\n\n\nThis project is receiving funding from the European Union\u2019s Horizon 2020 research and innovation programme under grant agreement nr. 732546 (DECODEproject).\n\n\nBuild instructions\n\n\nPre-built binaries are available here https://sdk.dyne.org:4443/view/decode/ - this section is optional for those who want to build this software from source.\n\n\nThe Zenroom compiles the same base sourcecode to 3 different POSIX\ncompatible ELF binary targets. They are:\n\n\n\n\nShared executable linked to a system-wide libc, libm and libpthread (mostly for debugging)\n\n\nFully static executable linked to musl-libc (to be operated on embedded platforms)\n\n\nJavascript module to be operated from a browser or NodeJS (for web based operations)\n\n\n\n\nIf you have cloned this source code from git, then do:\n\n\ngit submodule update --init --recursive\n\n\n\n\nThen first build the shared executable environment:\n\n\nmake shared\n\n\n\n\nTo run tests:\n\n\nmake check-shared\n\n\n\n\nTo build the static environment:\n\n\nmake bootstrap\nmake static\nmake check-static\n\n\n\n\nFor the Javascript and WebAssembly modules the Zenroom provides various targets provided by emscripten which must be installed and loaded in the environment according to the emsdk's instructions :\n\n\nmake js\nmake wasm\nmake html\n\n\n\n\nCrypto functionalities\n\n\nThe Zenroom language interpreter includes statically the following cryptographic primitives:\n\n\n\n\nNorx\n authenticated encryption with additional data (AEAD) - this is the default 64-4-1 variant (256-bit key and nonce, 4 rounds)\n\n\nBlake2b\n cryptographic hash function\n\n\nArgon2i\n, a modern key derivation function based on Blake2. Like \nscrypt, it is designed to be expensive in both CPU and memory.\n\n\nCurve25519\n-based key exchange and public key encryption,\n\n\nEd25519\n-based signature function using Blake2b hash instead of sha512,\n\n\n\n\nLegacy cryptographic functions include \nmd5\n, and \nrc4\n.\n\n\nEndoding and decoding functions are provided for \nbase64\n and \nbase58\n (for base58, the BitCoin encoding alphabet is used).\n\n\nCompression functions based on \nBriefLZ\n are also included.\n\n\nInclusion of classic NIST compliant \nRSA\n and \nDSA\n algorithms is in progress.\n\n\nOperating instructions\n\n\nThis software is work in progress and this section will be extended in the near future. Scripts found in the test/ directory provide good examples to start from.\n\n\nFrom \ncommand-line\n the Zenroom is operated passing files as arguments:\n\n\nUsage: zenroom [-c config] [-a arguments] script.lua\n\n\n\n\nFrom \njavascript\n the function \nzenroom_exec()\n is exposed with four arguments: three strings and one number from 1 to 3 indicating the verbosity of output on the console:\n\n\nint zenroom_exec(char *script, char *config, char *arguments, int verbosity)\n\n\n\n\nThe contents of the three strings cannot exceed 100k in size and are of different types:\n\n\n\n\nscript\n is a parsable LUA script, for example:\n\n\n\n\nt = \"The quick brown fox jumps over the lazy dog\"\npk, sk = keygen_sign_ed25519() -- signature keypair\nsig = sign_ed25519(sk, pk, t)\nassert(#sig == 64)\nassert(check_ed25519(sig, pk, t))\n\n\n\n\n\n\nconfig\n is also a parsable LUA script declaring variables, for example:\n\n\n\n\nmemory_limit = 100000\ninstruction_limit = 696969\noutput_limit = 64*1024\nlog_level = 7\nremove_entries = {\n    [''] = {'dofile','load', 'loadfile','newproxy'},\n    os = {'getenv','execute','exit','remove','rename',\n          'setlocale','tmpname'},\n    math = {'random', 'randomseed'}\n }\ndisable_modules = {io = 1}\n\n\n\n\n\n\narguments\n is a simple json, flat to the 1st level, declaring key/value pair strings, for example:\n\n\n\n\n{\n    \"secret\": \"The quick brown fox jumps over the lazy dog\",\n    \"salt\":   \"TKIpxzSJ1enTbnei\",\n    \"key\":    \"my symmetric password someone will guess one day\"\n}\n\n\n\n\nAll strings parsed in the arguments files will be available as pre-declared global variables to the script.\n\n\nAcknowledgements\n\n\nCopyright (C) 2017-2018 by Dyne.org foundation, Amsterdam\n\n\nDesigned, written and maintained by Denis Roio \njaromil@dyne.org\n\n\nIncludes code by:\n\n\n\n\nMozilla foundation (lua_sandbox)\n\n\nRich Felker, et al (musl-libc)\n\n\nMike Scott and kealan McCusker (milagro)\n\n\nPhil Leblanc (luazen)\n\n\nJoergen Ibsen (brieflz)\n\n\nLoup Vaillant (blake2b, argon2i, ed/x25519)\n\n\nSamuel Neves and Philipp Jovanovic (norx)\n\n\nLuiz Henrique de Figueiredo (base64)\n\n\nLuke Dashjr (base58)\n\n\nCameron Rich (md5)\n\n\nSergey Lyubka and Cesanta Software (frozen)\n\n\n\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License version 2 as\npublished by the Free Software Foundation.\n\n\nThis program is distributed in the hope that it will be useful, but\nWITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\nGeneral Public License for more details.\n\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see \nhttp://www.gnu.org/licenses/\n.",
            "title": "Introduction"
        },
        {
            "location": "/#zenroom-decode-project",
            "text": "Restricted execution environment  for cryptographic operations in a  Turing-incomplete language  based on LUA syntax and coarse-grained control of number of operations and memory used.  Zenroom follows a minimal design with security and portability in mind: it can be used in  untrusted distributed computing , for instance in distributed ledger or  blockchain smart contracts .  Zenroom compiles to fully static native binaries for embedded use, but also to javascript or webassembly modules for client-side use for instance in mobile applications.  With Zenroom is easy to write portable software using end-to-end client-side encryption using various classic and advanced cryptographic primitives to manage asymmetric keys, key derivation, hashing and signing functionalities.  This README documentation is operational. For more information on the purpose and design of this software see:   The DECODE Project website: https://decodeproject.eu  The Zenroom whitepaper and API documentation: https://decodeproject.github.io/zenroom   This project is receiving funding from the European Union\u2019s Horizon 2020 research and innovation programme under grant agreement nr. 732546 (DECODEproject).",
            "title": "Zenroom - DECODE project"
        },
        {
            "location": "/#build-instructions",
            "text": "Pre-built binaries are available here https://sdk.dyne.org:4443/view/decode/ - this section is optional for those who want to build this software from source.  The Zenroom compiles the same base sourcecode to 3 different POSIX\ncompatible ELF binary targets. They are:   Shared executable linked to a system-wide libc, libm and libpthread (mostly for debugging)  Fully static executable linked to musl-libc (to be operated on embedded platforms)  Javascript module to be operated from a browser or NodeJS (for web based operations)   If you have cloned this source code from git, then do:  git submodule update --init --recursive  Then first build the shared executable environment:  make shared  To run tests:  make check-shared  To build the static environment:  make bootstrap\nmake static\nmake check-static  For the Javascript and WebAssembly modules the Zenroom provides various targets provided by emscripten which must be installed and loaded in the environment according to the emsdk's instructions :  make js\nmake wasm\nmake html",
            "title": "Build instructions"
        },
        {
            "location": "/#crypto-functionalities",
            "text": "The Zenroom language interpreter includes statically the following cryptographic primitives:   Norx  authenticated encryption with additional data (AEAD) - this is the default 64-4-1 variant (256-bit key and nonce, 4 rounds)  Blake2b  cryptographic hash function  Argon2i , a modern key derivation function based on Blake2. Like \nscrypt, it is designed to be expensive in both CPU and memory.  Curve25519 -based key exchange and public key encryption,  Ed25519 -based signature function using Blake2b hash instead of sha512,   Legacy cryptographic functions include  md5 , and  rc4 .  Endoding and decoding functions are provided for  base64  and  base58  (for base58, the BitCoin encoding alphabet is used).  Compression functions based on  BriefLZ  are also included.  Inclusion of classic NIST compliant  RSA  and  DSA  algorithms is in progress.",
            "title": "Crypto functionalities"
        },
        {
            "location": "/#operating-instructions",
            "text": "This software is work in progress and this section will be extended in the near future. Scripts found in the test/ directory provide good examples to start from.  From  command-line  the Zenroom is operated passing files as arguments:  Usage: zenroom [-c config] [-a arguments] script.lua  From  javascript  the function  zenroom_exec()  is exposed with four arguments: three strings and one number from 1 to 3 indicating the verbosity of output on the console:  int zenroom_exec(char *script, char *config, char *arguments, int verbosity)  The contents of the three strings cannot exceed 100k in size and are of different types:   script  is a parsable LUA script, for example:   t = \"The quick brown fox jumps over the lazy dog\"\npk, sk = keygen_sign_ed25519() -- signature keypair\nsig = sign_ed25519(sk, pk, t)\nassert(#sig == 64)\nassert(check_ed25519(sig, pk, t))   config  is also a parsable LUA script declaring variables, for example:   memory_limit = 100000\ninstruction_limit = 696969\noutput_limit = 64*1024\nlog_level = 7\nremove_entries = {\n    [''] = {'dofile','load', 'loadfile','newproxy'},\n    os = {'getenv','execute','exit','remove','rename',\n          'setlocale','tmpname'},\n    math = {'random', 'randomseed'}\n }\ndisable_modules = {io = 1}   arguments  is a simple json, flat to the 1st level, declaring key/value pair strings, for example:   {\n    \"secret\": \"The quick brown fox jumps over the lazy dog\",\n    \"salt\":   \"TKIpxzSJ1enTbnei\",\n    \"key\":    \"my symmetric password someone will guess one day\"\n}  All strings parsed in the arguments files will be available as pre-declared global variables to the script.",
            "title": "Operating instructions"
        },
        {
            "location": "/#acknowledgements",
            "text": "Copyright (C) 2017-2018 by Dyne.org foundation, Amsterdam  Designed, written and maintained by Denis Roio  jaromil@dyne.org  Includes code by:   Mozilla foundation (lua_sandbox)  Rich Felker, et al (musl-libc)  Mike Scott and kealan McCusker (milagro)  Phil Leblanc (luazen)  Joergen Ibsen (brieflz)  Loup Vaillant (blake2b, argon2i, ed/x25519)  Samuel Neves and Philipp Jovanovic (norx)  Luiz Henrique de Figueiredo (base64)  Luke Dashjr (base58)  Cameron Rich (md5)  Sergey Lyubka and Cesanta Software (frozen)   This program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License version 2 as\npublished by the Free Software Foundation.  This program is distributed in the hope that it will be useful, but\nWITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\nGeneral Public License for more details.  You should have received a copy of the GNU General Public License\nalong with this program.  If not, see  http://www.gnu.org/licenses/ .",
            "title": "Acknowledgements"
        },
        {
            "location": "/design/",
            "text": "Introduction\n\n\nThe main way to communicate with a DECODE node and operate its functions is via a language, rather than an API. All read and write operations affecting entitlements and accessing attributes can be expressed in a smart-rule language, which we intend to design and develop to become a robust open standard for authorisation around personal data. The DECODE smart-rule language will aim to naturally avoid complex constructions and define sets of transformations that can be then easily represented with visual metaphors; in terms of programming language it will be deterministic and side effect-free in order to better prove its correctness.\n\n\nAt this stage of the research, this document is split in 3 sections:\n\n\n\n\n\n\na brief \"state of the art\" analysis, considering existing blockchain-based languages and in particular the most popular \"Solidity\" supported by the Ethereum virtual machine.\n\n\n\n\n\n\na brief enumeration of the characteristics of this implementation and an abstraction from it, to individuate the fundamental features a smart-rule language should have in the context of permissionless, distributed computing.\n\n\n\n\n\n\na set of technical recommendations for the development of smart-rules in DECODE\n\n\n\n\n\n\nThis document is not speculative, but is companion to an actual implementation being developed during the course of DECODE's project: the \n\"zenroom\" (link)\n.\n\n\nA new memory model\n\n\nIn computing science the concepts of HEAP and STACK are well known and represent the different areas of memory in which a single computer can store code, address it while executing it and store data on which the code can read and write. With the advent of \"virtual machines\" (abstract computing machines like JVM or BEAM, not virtualised operating systems) the implementation of logic behind the HEAP and STACK became more abstract and not anymore bound to a specific hardware architecture, therefore leaving more space for the portability of code and creative memory management practices (like garbage collection). It is also thanks to the use of virtual machines that high level languages became closer to the way humans think, rather than the way machines work, benefitting creativity, awareness and auditability [@mccartney2002rethinking]. This is an important vector of innovation for the language implementation in DECODE, since it is desirable for this project to implement a language that is close to the way humans think.\n\n\nWith the advent of distributed computing technology and blockchain implementations there is a growing necessity to conceive the HEAP and STACK differently [@DBLP:conf/ipps/PizkaR02], mostly because there are many more different conditions for memory bound to its persistence, read/write speed, mutability, distribution etc.\n\n\nThe underpinning of this document, elaborated on the term \"blockchain language\", is that a new \"distributed ledger\", as collective and immutable memory space, can be addressed with code running on different machines.\n\n\nA \"blockchain language\" then is a language designed to interact with a \"distributed ledger\".  A distributed ledger is a log of \"signed events\" whose authenticity can be verified by any node being part of the network; taking part of a network can be regulated by permissions (in a so called \"permissioned blockchain\") or completely open to any participant complying to the protocol (so called \"permissionless blockchain\").\n\n\nThis document intentionally leaves aside considerations about the consensus algorithm of a blockchain-based network, which are very specific issues concerning the implementation of a blockchain and are covered by other research tasks in DECODE. While assuming an ideal condition for fault tolerance will be provided by other research tasks in DECODE, this research will continue focusing on the function that the distributed ledger has for the distributed computation of a language, assuming the most interesting case of a permissionless blockchain (an open network) since that is the most ambitious research goal for DECODE as stated for the development of Chainspace [@al2017chainspace].\n\n\n1. Blockchain languages\n\n\nThis section is a brief exploration of the main language implementations working on blockchains. Far from being an exhaustive overview, it highlights the characteristics of these implementations and most importantly the approach followed in building virtual machines that are based on assembler-like operation codes and languages that compile to these.\n\n\nThe conclusion of this section is that the blockchain languages so far existing are designed with a product-oriented mindset, starting from the implementation of a virtual machine that can process OP_CODEs. Higher level languages build upon it, parsing higher level syntactics and semantics and compiling them into a series of OP_CODEs. This is the natural way most languages like ASM, C and C++ have evolved through the years.\n\n\nArguably, a task-oriented mindset should be assumed when re-designing a new blockchain language for DECODE: that would be the equivalent of a human-centered research and design process. The opportunity for innovating the field lies in abandoning the OP_CODE approach and instead build an External Domain Specific Language [@fowler2010domain] using an existing grammar to do the Syntax-Directed Translation. The Semantic Model can be then a coarse-grained implementation that can sync computations with blockchain-based deterministic conditionals. \n\n\nBitcoin's SCRIPT\n\n\nStarting with the \"SCRIPT\" implementation in Bitcoin [@nakamoto2008bitcoin] and ending with the Ethereum Virtual Machine implementation, it is clear that blockchain technologies were developed with the concept of \"distributed computation\" in mind. The scenario is that of a network of computers that, at any point in time, can execute the same code on a part of the distributed ledger and that execution would yield to the same results, making the computation completely deterministic.\n\n\nThe distributed computation is made by blockchain nodes that act as sort of \"virtual machines\" and process \"operation codes\" (OP_CODE) just like a computer does. These OP_CODES in fact resemble assembler language operations. \n\n\nIn Bitcoin the so called SCRIPT implementation had an unfinished number of \"OP_CODE\" commands (operation codes) at the time of its popularisation and, around the 0.6 release, the feature was in large part deactivated to ensure the security of the network, since it was assessed by most developers involved that the Bitcoin implementation of SCRIPT was unfinished and represented threats to the network. Increasing the complexity of code that can be executed by nodes of an open network is always a risk, since code can contain arbitrary operations and commands that may lead to unpredictable results affecting both the single node and the whole network. The shortcomings of the SCRIPT in Bitcoin were partially addressed: its space for OP_RETURN [@roio2015d4] became the contested ground for payloads [@sward2017data] that could be interpreted by other VMs, as well the limit was partially circumvented by moving more complex logic in touch with the Bitcoin blockchain [@aron2012bitcoin], for instance using the techniques adopted by Mastercoin [@mastercoin2013willett] and \"sidechains\" as Counterparty [@bocek2018smart] or \"pegged sidechains\" [@back2014enabling] implementations. All these are implementations of VMs that run in parallel to Bitcoin, can \"peg\" their results on the main Bitcoin blockchain and still execute more complex operations in another space, where tokens and conditions can be created and affect different memory spaces and distributed ledgers.\n\n\nLanguages implemented so far for this task are capable of executing single OP_CODEs: implementations are very much \"machine-oriented\" and focused on reproducing the behaviour of a turing-complete machine [@DBLP:conf/birthday/WegnerEB12] capable of executing generic computing tasks.\n\n\nThe Ethereum VM\n\n\nThe Ethereum Virtual Machine is arguably the most popular implementation of a language that can be computed by a distributed and decentralised network of virtual machines that have all their own HEAP and STACK, but all share the same immutable distributed ledger on which \"global\" values and the code (contracts) manipulating them can be inscribed and read from.\n\n\nComputation in the EVM is done using a stack-based bytecode language that is like a cross between Bitcoin Script, traditional assembly and Lisp (the Lisp part being due to the recursive message-sending functionality). A program in EVM is a sequence of opcodes, like this:\n\n\nPUSH1 0 CALLDATALOAD SLOAD NOT PUSH1 9 JUMPI STOP JUMPDEST PUSH1 32 CALLDATALOAD PUSH1 0 CALLDATALOAD SSTORE\n\n\n\n\nThe purpose of this particular contract is to serve as a name registry; anyone can send a message containing 64 bytes of data, 32 for the key and 32 for the value. The contract checks if the key has already been registered in storage, and if it has not been then the contract registers the value at that key. The address of the new contract is deterministic and calculated on the sending address and the number of times that the sending account has made a transaction before.\n\n\nThe EVM is a simple stack-based architecture. The word size of the machine (and thus size of stack item) is 256-bit. This was chosen to fit a simple word-addressed byte array. The stack has a maximum size of 1024. The machine also has an independent storage model; this is similar in concept to the memory but rather than a byte array, it is a word- addressable word array. Unlike memory, which is volatile, storage is nonvolatile and is maintained as part of the system state. All locations in both storage and memory are well-defined initially as zero.\n\n\nThe machine does not follow the standard von Neumann architecture. Rather than storing program code in generally-accessible memory or storage, it is stored separately in a virtual ROM that can only be interacted with via a specific instruction.  The machine can have exceptional execution for several reasons, including stack underflows and invalid instructions. Like the out-of-gas (OOG) exception, they do not leave state changes intact. Rather, the machine halts immediately and reports the issue to the execution agent (either the transaction processor or, recursively, the spawning execution environment) which will deal with it separately [@wood2014ethereum].\n\n\nThe resulting implementation consists of a list of OP_CODEs whose execution requires a \"price\" to be paid (Ethereum's currency for the purpose is called \"gas\"). This way an incentive is created for running nodes: a fee is paid to nodes for computing the contracts and confirming the outcomes of their execution. This feature technically defines the Ethereum VM as implementing an almost Turing-complete machine since its execution is conditioned by the availability of funds for computation. This approach relies on the fact that each operation is executed at a constant unit of speed.\n\n\nOn top of these OP_CODEs the \"Solidity\" language was developed as a high-level language that compiles to OP_CODE sequences. Solidity aims to make it easier for people to program \"smart contracts\". But it is arguable that the Solidity higher-level language, widely present in all Ethereum related literature, carries several problems: the shortcomings of its design can be indirectly related to some well-known disasters provoked by flaws in published contracts. To quickly summarise some flaws:\n\n\n\n\nthere is no garbage collector nor manual memory management\n\n\nfloating point numbers are not supported\n\n\nthere are known security flaws in the compiler\n\n\nthe syntax of loops and arrays is confusing\n\n\nevery type is 256bits wide, including bytes\n\n\nthere is no string manipulation support\n\n\nfunctions can return only statically sized arrays\n\n\n\n\nTo overcome the shortcomings and create some shared base of reliable implementations, programmers using Solidity currently adopt \"standard\" token implementation libraries with basic functions that are proven to be working reliably: known as ERC20, the standard is made for tokens to be supported across different wallets and to be reliable. Yet even with a recent update to a new version (ERC232) the typical code constructs that are known to be working are full of checks (assert calls) to insure the reliability of the calling code. For example, typical arithmetic operations need to be implemented in Solidity as:\n\n\n\n  function times(uint a, uint b) constant private returns (uint) {\n    uint c = a * b;\n    assert(a == 0 || c / a == b);\n    return c;\n  }\n\n  function minus(uint a, uint b) constant private returns (uint) {\n    assert(b <= a);\n    return a - b;\n  }\n\n  function plus(uint a, uint b) constant private returns (uint) {\n    uint c = a + b;\n    assert(c>=a);\n    return c;\n  }\n\n\n\n\nIt must be also noted that the EVM allows calling external contracts that can take over the control flow and make changes to data that the calling function wasn't expecting. This class of bug can take many forms and all of major bugs that led to the DAO's collapse [@o2017smart] were bugs of this sort.\n\n\nDespite the shortcomings, nowadays Solidity is widely used: it is the most used \"blockchain language\" supporting \"smart-contracts\" in the world.\n\n\n2. Language Security\n\n\nThis chapter will quickly establish the underpinnings of a smart rule language in DECODE, starting from its most theoretical assumptions, to conclude with specific requirements. The chapter will concentrate on the recent corpus developed by research on language-theoretic security\" (LangSec). Here below we include a brief explanation condensed from the information material of the LangSec.org project hosted at IEEE, which is informed by the collective experience of the exploit development community, since exploitation is a practical exploration of the space of unanticipated state, its prevention or containment.\n\n\n\"In a nutshell [...] LangSec is the idea that many security issues can be avoided by applying a standard process to input processing and protocol design: the acceptable input to a program should be well-defined (i.e., via a grammar), as simple as possible (on the Chomsky scale of syntactic complexity), and fully validated before use (by a dedicated parser of appropriate but not excessive power in the Chomsky hierarchy of automata).\" [@DBLP:conf/secdev/MomotBHP16]\n\n\nLangSec is a design and programming philosophy that focuses on formally correct and verifiable input handling throughout all phases of the software development lifecycle. In doing so, it offers a practical method of assurance of software free from broad and currently dominant classes of bugs and vulnerabilities related to incorrect parsing and interpretation of messages between software components (packets, protocol messages, file formats, function parameters, etc.).\n\n\nThis design and programming paradigm begins with a description of valid inputs to a program as a formal language (such as a grammar). The purpose of such a disciplined specification is to cleanly separate the input-handling code and processing code. A LangSec-compliant design properly transforms input-handling code into a recognizer for the input language; this recognizer rejects non-conforming inputs and transforms conforming inputs to structured data (such as an object or a tree structure, ready for type- or value-based pattern matching). The processing code can then access the structured data (but not the raw inputs or parsers temporary data artifacts) under a set of assumptions regarding the accepted inputs that are enforced by the recognizer.\n\n\nThis approach leads to several advantages:\n\n\n\n\nproduce verifiable recognizers, free of typical classes of ad-hoc parsing bugs\n\n\nproduce verifiable, composable implementations of distributed systems that ensure equivalent parsing of messages by all components and eliminate exploitable differences in message interpretation by the elements of a distributed system\n\n\nmitigate the common risks of ungoverned development by explicitly exposing the processing dependencies on the parsed input.\n\n\n\n\nAs a design philosophy, LangSec focuses on a particular choice of verification trade-offs: namely, correctness and computational equivalence of input processors.\n\n\nThreats when developing a language\n\n\nAs one engages the task of developing a language there are four main threats to be identified, well described in LangSec literature:\n\n\nAd-hoc notions of input validity\n\n\nFormal verification of input handlers is impossible without formal language-theoretic specification of their inputs, whether these inputs are packets, messages, protocol units, or file formats. Therefore, design of an input-handling program must start with such a formal specification.  Once specified, the input language should be reduced to the least complex class requiring the least computational power to recognize. Considering the tendency of hand-coded programs to admit extra state and computation paths, computational power susceptible to crafted inputs should be minimized whenever possible. Whenever the input language is allowed to achieve Turing-complete power, input validation becomes undecidable; such situations should be avoided. For example, checking 'benignness' of arbitrary Javascript or even an HTML5+CSS page is a losing proposition.\n\n\nParser differentials\n\n\nMutual misinterpretation between system components. Verifiable composition is impossible without the means of establishing parsing equivalence between different components of a distributed system. Different interpretation of messages or data streams by components breaks any assumptions that components adhere to a shared specification and so introduces inconsistent state and unanticipated computation [@DBLP:conf/secdev/MomotBHP16]. In addition, it breaks any security schemes in which equivalent parsing of messages is a formal requirement, such as the contents of a certificate or of a signed message being interpreted identically, for example a X.509 Certificate Signing Request as seen by a Certificate Authority vs. the signed certificates as seen by the clients or signed app package contents as seen by the signature verifier versus the same content as seen by the installer (as in the recent Android Master Key bug [@freeman2013exploit]). An input language specification stronger than deterministic context-free makes the problem of establishing parser equivalence undecidable. Such input languages and systems whose trustworthiness is predicated on the component parser equivalence should be avoided. Logical programming using Prolog for instance, or languages like Scheme derived from LISP, or OCaml or Erlang would match then our requirements, but they aren't as usable as desired. As a partial solution to this problem the DECODE language parser (and all its components and eventually linked shared libraries) should be self-contained and clearly versioned and hashed and its hash verified before every computation. \n\n\nMixing of input recognition and processing\n\n\nMixing of basic input validation (\"sanity checks\") and logically subsequent processing steps that belong only after the integrity of the entire message has been established makes validation hard or impossible. As a practical consequence, unanticipated reachable state exposed by such premature optimization explodes. This explosion makes principled analysis of the possible computation paths untenable. LangSec-style separation of the recognizer and processor code creates a natural partitioning that allows for simpler specification-based verification and management of code. In such designs, effective elimination of exploit-enabling implicit data flows can be achieved by simple systems memory isolation primitives.\n\n\nLanguage specification drift\n\n\nA common practice encouraged by rapid software development is the unconstrained addition of new features to software components and their corresponding reflection in input language specifications. Expressing complex ideas in hastily written code is a hallmark of such development practices. In essence, adding new input feature requirements to an already-underspecified input language compounds the explosion of state and computational paths.\n\n\n3. Smart-rules language\n\n\nIn light of our study of blockchain languages, use-cases and privacy by design guidelines in DECODE, this section lists three functional requirements and three usability requirements influencing the design patterns for our language.\n\n\nThe conclusion of this section is best described adopting once again the DSL terminology and the patterns established by Fowler. The DECODE smart-rule language is an external DSL implemented using a Syntax-Directed Translation. Its Semantic Model leads to coarse-grained tasks to be executed on the network, perhaps following a Dependency Network approach.\n\n\nA tempting alternative can be that of a Production Rule System, but this way we would hide too much the internal processes in DECODE, which should be transparent and comprehensible to anyone with a beginner knowledge of programming.\n\n\nAn addition to this approach can be that of equipping the language with tools for constraint programming and even a context of Satisfiability Modulo Theories [@barrett2009satisfiability] to check satisfying Program Termination Proofs [@bonfante2001algorithms].\n\n\nFunctional requirements\n\n\nOn the basis of the design considerations made in the previous chapters, here are listed the main requirements identified for the implementation of a smart-rule language in DECODE.\n\n\nDeterministic\n\n\nThis is an important feature common to all blockchain language implementations in use: that the language limits its operations to access only a fully deterministic environment. This means that, in any possible moment in time, any node can join the network and start computing contracts leading to results that are verifiable and confirmed by other nodes.\n\n\nIn other words, the environment accessed by the language is available to all nodes, there aren't variables that are \"private\" to a single node and may change the result by a change of their value.\n\n\nThe deterministic trait must be common also to the DECODE blockchain language for smart-rules, since it verifies a basic and necessary condition for blockchain based computing: that other nodes can verify and sign the results, reproducing them in their own execution environment. The computation leads to the same results that can be determined in different conditions, because all nodes have access to the same information necessary to the computation.\n\n\nTrustless\n\n\nWe define as trustless a language (also known as untrusted language) that allows the virtual machine to fence its execution, as in a \"sandbox\" or isolated execution environment, blocking access to unauthorised parts of the system.\n\n\nA language that can be run on a \"permissionless\" (public) blockchain is a language that can be interpreted by any node. In any moment a new node may claim the capacity to do so. This means that its parser, semantics and actions on the system must be designed to handle unknowns: any deviance and malevolent code should not affect the system.\n\n\nSolid\n\n\nThe language and the semantic model adopted by DECODE need to be capable of sandboxing untrusted code and providing security partitioning. Any process of execution should be strictly limited in what it can do. Any function or data passed to a node cannot break the sandbox in ways the participants did not intend.\n\n\nFor sensitive data structures, the use of proxy objects must be adopted as a security guard, only allowing the sandbox to call pre-approved methods and access pre-approved data.\n\n\nUsability requirements\n\n\nHere are listed the requirements emerging from an analysis of priorities about the human-machine interaction scenarios emerging from DECODE.\n\n\nSimple, graphical representation\n\n\nA visual programming environment (VPE) facilitates participants to directly re-configure the rules governing their data: this is highly desirable in DECODE, where such code must be transparent and understandable. The event-based blocks graphical metaphor seems the most desirable for the sort of processing in DECODE: it involves letting participants manipulate a series of graphical elements (blocks) that snap onto one another and that execute sequential programs.\n\n\nTest environment\n\n\nA reliable test environment is a fundamental component for a language deployed in mission critical situations, but also for a language dealing with the distribution of its computation and wide adoption by communities of developers in different fields. Languages that improve the developer's experience when writing and testing code directly impact the quality of the code produced.\n\n\nFor DECODE's language implementation it is necessary to have a testing environment designed into it and from the start to facilitate its growth at the same pace of the language itself. Also, a more advanced framework for testing that goes beyond the simple usage of asserts is desirable: while being very ambitious, the implementation of solid proof of termination mechanisms that are internal to the language should be contemplated on the long term.\n\n\nFirst-class data\n\n\nThis is a long-term requirement that should take into consideration the trade-off between feasibility, security and convenience. A data type is considered first-class in a programming language if instances of that type can be\n\n\n\n\nthe value of a variable\n\n\na member of an aggregate (array, list, etc.)\n\n\nan argument (input) to a procedure\n\n\nthe value returned by a procedure\n\n\nused without having a name (being the value of a variable)\n\n\n\n\nFor example, numbers are first-class in every language. Text strings are first-class in many languages, but not in C, in which the relevant first-class type is \u201cpointer to a character\u201d.\n\n\nIn DECODE it is desirable to establish data structures containing attributes and entitlements as first-class data to be seamlessly processed by the language.\n\n\nConclusion\n\n\nThis document is a very dense representation of language patterns and requirements to be adopted while implementing DECODE's language. Its feasibility has been verified with an extensive survey on available tools that can be used to implement this execution engine and are compatible with the DECODE licensing model.\n\n\nThis conclusion provides a brief list of components that can be used.\n\n\nSyntax-Directed Translation\n\n\nLua is an interpreted, cross-platform, embeddable, performant and low-footprint language. Lua's popularity is on the rise in the last couple of years [@costin2017lua]. Simple design and efficient usage of resources combined with its performance make it attractive for production web applications, even to big organizations such as Wikipedia, CloudFlare and GitHub. In addition to this, Lua is one of the preferred choices for programming embedded and IoT devices. This context allows an assumption of a large and growing Lua codebase yet to be assessed. This growing Lua codebase could be potentially driving production servers and an extremely large number of devices, some perhaps with mission-critical function for example in automotive or home-automation domains.\n\n\nLua stability has been extensively tested through a number of public applications including the adoption by the gaming industry for untrusted language processing in \"World of Warcraft\" scripting. It is ideal for implementing an external DSL using C or Python as a host language.\n\n\nLua is also tooled with a working VPE implementation for code visualisation in BLOCKS, allowing the project to jump-start into an early phase of prototyping DECODE smart-rules in a visual way and directly involving pilot participants.\n\n\nSatisfiability Modulo theories\n\n\nSatisfiability Modulo theories (SMT) is an area of automated deduction that studies methods for checking the satisfiability of first-order formulas with respect to some logical theory of interest [@barrett2009satisfiability]. It differs from general automated deduction in that the background theory need not be finitely or even first-order axiomatizable, and specialized inference methods are used for each theory. By being theory-specific and restricting their language to certain classes of formulas (such as, typically but not exclusively, quantifier-free formulas), these specialized methods can be implemented in solvers that are more efficient in practice than general-purpose theorem provers.\n\n\nWhile SMT techniques have been traditionally used to support deductive software verification, they are now finding applications in other areas of computer science such as planning, model checking and automated test generation. Typical theories of interest in these applications include formalizations of arithmetic, arrays, bit vectors, algebraic datatypes, equality with uninterpreted functions, and various combinations of these. \n\n\nConstraint-satisfaction is crucial to software and hardware verification and static program analsysis [@de2011satisfiability] among the other possible applications.\n\n\nDECODE will benefit from including SMT capabilities into the design at an early stage: even if not immediately exploited, their inclusion will keep the horizons for language development open while permitting its application in mission critical roles. The best implementation to start from in this experimentation seems to be the free and open source software \"Yices SMT Solver\" published by the Computer Science Laboratory of the Stanford Research Institute (SRI International).",
            "title": "Design principles"
        },
        {
            "location": "/design/#introduction",
            "text": "The main way to communicate with a DECODE node and operate its functions is via a language, rather than an API. All read and write operations affecting entitlements and accessing attributes can be expressed in a smart-rule language, which we intend to design and develop to become a robust open standard for authorisation around personal data. The DECODE smart-rule language will aim to naturally avoid complex constructions and define sets of transformations that can be then easily represented with visual metaphors; in terms of programming language it will be deterministic and side effect-free in order to better prove its correctness.  At this stage of the research, this document is split in 3 sections:    a brief \"state of the art\" analysis, considering existing blockchain-based languages and in particular the most popular \"Solidity\" supported by the Ethereum virtual machine.    a brief enumeration of the characteristics of this implementation and an abstraction from it, to individuate the fundamental features a smart-rule language should have in the context of permissionless, distributed computing.    a set of technical recommendations for the development of smart-rules in DECODE    This document is not speculative, but is companion to an actual implementation being developed during the course of DECODE's project: the  \"zenroom\" (link) .",
            "title": "Introduction"
        },
        {
            "location": "/design/#a-new-memory-model",
            "text": "In computing science the concepts of HEAP and STACK are well known and represent the different areas of memory in which a single computer can store code, address it while executing it and store data on which the code can read and write. With the advent of \"virtual machines\" (abstract computing machines like JVM or BEAM, not virtualised operating systems) the implementation of logic behind the HEAP and STACK became more abstract and not anymore bound to a specific hardware architecture, therefore leaving more space for the portability of code and creative memory management practices (like garbage collection). It is also thanks to the use of virtual machines that high level languages became closer to the way humans think, rather than the way machines work, benefitting creativity, awareness and auditability [@mccartney2002rethinking]. This is an important vector of innovation for the language implementation in DECODE, since it is desirable for this project to implement a language that is close to the way humans think.  With the advent of distributed computing technology and blockchain implementations there is a growing necessity to conceive the HEAP and STACK differently [@DBLP:conf/ipps/PizkaR02], mostly because there are many more different conditions for memory bound to its persistence, read/write speed, mutability, distribution etc.  The underpinning of this document, elaborated on the term \"blockchain language\", is that a new \"distributed ledger\", as collective and immutable memory space, can be addressed with code running on different machines.  A \"blockchain language\" then is a language designed to interact with a \"distributed ledger\".  A distributed ledger is a log of \"signed events\" whose authenticity can be verified by any node being part of the network; taking part of a network can be regulated by permissions (in a so called \"permissioned blockchain\") or completely open to any participant complying to the protocol (so called \"permissionless blockchain\").  This document intentionally leaves aside considerations about the consensus algorithm of a blockchain-based network, which are very specific issues concerning the implementation of a blockchain and are covered by other research tasks in DECODE. While assuming an ideal condition for fault tolerance will be provided by other research tasks in DECODE, this research will continue focusing on the function that the distributed ledger has for the distributed computation of a language, assuming the most interesting case of a permissionless blockchain (an open network) since that is the most ambitious research goal for DECODE as stated for the development of Chainspace [@al2017chainspace].",
            "title": "A new memory model"
        },
        {
            "location": "/design/#1-blockchain-languages",
            "text": "This section is a brief exploration of the main language implementations working on blockchains. Far from being an exhaustive overview, it highlights the characteristics of these implementations and most importantly the approach followed in building virtual machines that are based on assembler-like operation codes and languages that compile to these.  The conclusion of this section is that the blockchain languages so far existing are designed with a product-oriented mindset, starting from the implementation of a virtual machine that can process OP_CODEs. Higher level languages build upon it, parsing higher level syntactics and semantics and compiling them into a series of OP_CODEs. This is the natural way most languages like ASM, C and C++ have evolved through the years.  Arguably, a task-oriented mindset should be assumed when re-designing a new blockchain language for DECODE: that would be the equivalent of a human-centered research and design process. The opportunity for innovating the field lies in abandoning the OP_CODE approach and instead build an External Domain Specific Language [@fowler2010domain] using an existing grammar to do the Syntax-Directed Translation. The Semantic Model can be then a coarse-grained implementation that can sync computations with blockchain-based deterministic conditionals.",
            "title": "1. Blockchain languages"
        },
        {
            "location": "/design/#bitcoins-script",
            "text": "Starting with the \"SCRIPT\" implementation in Bitcoin [@nakamoto2008bitcoin] and ending with the Ethereum Virtual Machine implementation, it is clear that blockchain technologies were developed with the concept of \"distributed computation\" in mind. The scenario is that of a network of computers that, at any point in time, can execute the same code on a part of the distributed ledger and that execution would yield to the same results, making the computation completely deterministic.  The distributed computation is made by blockchain nodes that act as sort of \"virtual machines\" and process \"operation codes\" (OP_CODE) just like a computer does. These OP_CODES in fact resemble assembler language operations.   In Bitcoin the so called SCRIPT implementation had an unfinished number of \"OP_CODE\" commands (operation codes) at the time of its popularisation and, around the 0.6 release, the feature was in large part deactivated to ensure the security of the network, since it was assessed by most developers involved that the Bitcoin implementation of SCRIPT was unfinished and represented threats to the network. Increasing the complexity of code that can be executed by nodes of an open network is always a risk, since code can contain arbitrary operations and commands that may lead to unpredictable results affecting both the single node and the whole network. The shortcomings of the SCRIPT in Bitcoin were partially addressed: its space for OP_RETURN [@roio2015d4] became the contested ground for payloads [@sward2017data] that could be interpreted by other VMs, as well the limit was partially circumvented by moving more complex logic in touch with the Bitcoin blockchain [@aron2012bitcoin], for instance using the techniques adopted by Mastercoin [@mastercoin2013willett] and \"sidechains\" as Counterparty [@bocek2018smart] or \"pegged sidechains\" [@back2014enabling] implementations. All these are implementations of VMs that run in parallel to Bitcoin, can \"peg\" their results on the main Bitcoin blockchain and still execute more complex operations in another space, where tokens and conditions can be created and affect different memory spaces and distributed ledgers.  Languages implemented so far for this task are capable of executing single OP_CODEs: implementations are very much \"machine-oriented\" and focused on reproducing the behaviour of a turing-complete machine [@DBLP:conf/birthday/WegnerEB12] capable of executing generic computing tasks.",
            "title": "Bitcoin's SCRIPT"
        },
        {
            "location": "/design/#the-ethereum-vm",
            "text": "The Ethereum Virtual Machine is arguably the most popular implementation of a language that can be computed by a distributed and decentralised network of virtual machines that have all their own HEAP and STACK, but all share the same immutable distributed ledger on which \"global\" values and the code (contracts) manipulating them can be inscribed and read from.  Computation in the EVM is done using a stack-based bytecode language that is like a cross between Bitcoin Script, traditional assembly and Lisp (the Lisp part being due to the recursive message-sending functionality). A program in EVM is a sequence of opcodes, like this:  PUSH1 0 CALLDATALOAD SLOAD NOT PUSH1 9 JUMPI STOP JUMPDEST PUSH1 32 CALLDATALOAD PUSH1 0 CALLDATALOAD SSTORE  The purpose of this particular contract is to serve as a name registry; anyone can send a message containing 64 bytes of data, 32 for the key and 32 for the value. The contract checks if the key has already been registered in storage, and if it has not been then the contract registers the value at that key. The address of the new contract is deterministic and calculated on the sending address and the number of times that the sending account has made a transaction before.  The EVM is a simple stack-based architecture. The word size of the machine (and thus size of stack item) is 256-bit. This was chosen to fit a simple word-addressed byte array. The stack has a maximum size of 1024. The machine also has an independent storage model; this is similar in concept to the memory but rather than a byte array, it is a word- addressable word array. Unlike memory, which is volatile, storage is nonvolatile and is maintained as part of the system state. All locations in both storage and memory are well-defined initially as zero.  The machine does not follow the standard von Neumann architecture. Rather than storing program code in generally-accessible memory or storage, it is stored separately in a virtual ROM that can only be interacted with via a specific instruction.  The machine can have exceptional execution for several reasons, including stack underflows and invalid instructions. Like the out-of-gas (OOG) exception, they do not leave state changes intact. Rather, the machine halts immediately and reports the issue to the execution agent (either the transaction processor or, recursively, the spawning execution environment) which will deal with it separately [@wood2014ethereum].  The resulting implementation consists of a list of OP_CODEs whose execution requires a \"price\" to be paid (Ethereum's currency for the purpose is called \"gas\"). This way an incentive is created for running nodes: a fee is paid to nodes for computing the contracts and confirming the outcomes of their execution. This feature technically defines the Ethereum VM as implementing an almost Turing-complete machine since its execution is conditioned by the availability of funds for computation. This approach relies on the fact that each operation is executed at a constant unit of speed.  On top of these OP_CODEs the \"Solidity\" language was developed as a high-level language that compiles to OP_CODE sequences. Solidity aims to make it easier for people to program \"smart contracts\". But it is arguable that the Solidity higher-level language, widely present in all Ethereum related literature, carries several problems: the shortcomings of its design can be indirectly related to some well-known disasters provoked by flaws in published contracts. To quickly summarise some flaws:   there is no garbage collector nor manual memory management  floating point numbers are not supported  there are known security flaws in the compiler  the syntax of loops and arrays is confusing  every type is 256bits wide, including bytes  there is no string manipulation support  functions can return only statically sized arrays   To overcome the shortcomings and create some shared base of reliable implementations, programmers using Solidity currently adopt \"standard\" token implementation libraries with basic functions that are proven to be working reliably: known as ERC20, the standard is made for tokens to be supported across different wallets and to be reliable. Yet even with a recent update to a new version (ERC232) the typical code constructs that are known to be working are full of checks (assert calls) to insure the reliability of the calling code. For example, typical arithmetic operations need to be implemented in Solidity as:  \n  function times(uint a, uint b) constant private returns (uint) {\n    uint c = a * b;\n    assert(a == 0 || c / a == b);\n    return c;\n  }\n\n  function minus(uint a, uint b) constant private returns (uint) {\n    assert(b <= a);\n    return a - b;\n  }\n\n  function plus(uint a, uint b) constant private returns (uint) {\n    uint c = a + b;\n    assert(c>=a);\n    return c;\n  }  It must be also noted that the EVM allows calling external contracts that can take over the control flow and make changes to data that the calling function wasn't expecting. This class of bug can take many forms and all of major bugs that led to the DAO's collapse [@o2017smart] were bugs of this sort.  Despite the shortcomings, nowadays Solidity is widely used: it is the most used \"blockchain language\" supporting \"smart-contracts\" in the world.",
            "title": "The Ethereum VM"
        },
        {
            "location": "/design/#2-language-security",
            "text": "This chapter will quickly establish the underpinnings of a smart rule language in DECODE, starting from its most theoretical assumptions, to conclude with specific requirements. The chapter will concentrate on the recent corpus developed by research on language-theoretic security\" (LangSec). Here below we include a brief explanation condensed from the information material of the LangSec.org project hosted at IEEE, which is informed by the collective experience of the exploit development community, since exploitation is a practical exploration of the space of unanticipated state, its prevention or containment.  \"In a nutshell [...] LangSec is the idea that many security issues can be avoided by applying a standard process to input processing and protocol design: the acceptable input to a program should be well-defined (i.e., via a grammar), as simple as possible (on the Chomsky scale of syntactic complexity), and fully validated before use (by a dedicated parser of appropriate but not excessive power in the Chomsky hierarchy of automata).\" [@DBLP:conf/secdev/MomotBHP16]  LangSec is a design and programming philosophy that focuses on formally correct and verifiable input handling throughout all phases of the software development lifecycle. In doing so, it offers a practical method of assurance of software free from broad and currently dominant classes of bugs and vulnerabilities related to incorrect parsing and interpretation of messages between software components (packets, protocol messages, file formats, function parameters, etc.).  This design and programming paradigm begins with a description of valid inputs to a program as a formal language (such as a grammar). The purpose of such a disciplined specification is to cleanly separate the input-handling code and processing code. A LangSec-compliant design properly transforms input-handling code into a recognizer for the input language; this recognizer rejects non-conforming inputs and transforms conforming inputs to structured data (such as an object or a tree structure, ready for type- or value-based pattern matching). The processing code can then access the structured data (but not the raw inputs or parsers temporary data artifacts) under a set of assumptions regarding the accepted inputs that are enforced by the recognizer.  This approach leads to several advantages:   produce verifiable recognizers, free of typical classes of ad-hoc parsing bugs  produce verifiable, composable implementations of distributed systems that ensure equivalent parsing of messages by all components and eliminate exploitable differences in message interpretation by the elements of a distributed system  mitigate the common risks of ungoverned development by explicitly exposing the processing dependencies on the parsed input.   As a design philosophy, LangSec focuses on a particular choice of verification trade-offs: namely, correctness and computational equivalence of input processors.",
            "title": "2. Language Security"
        },
        {
            "location": "/design/#threats-when-developing-a-language",
            "text": "As one engages the task of developing a language there are four main threats to be identified, well described in LangSec literature:",
            "title": "Threats when developing a language"
        },
        {
            "location": "/design/#ad-hoc-notions-of-input-validity",
            "text": "Formal verification of input handlers is impossible without formal language-theoretic specification of their inputs, whether these inputs are packets, messages, protocol units, or file formats. Therefore, design of an input-handling program must start with such a formal specification.  Once specified, the input language should be reduced to the least complex class requiring the least computational power to recognize. Considering the tendency of hand-coded programs to admit extra state and computation paths, computational power susceptible to crafted inputs should be minimized whenever possible. Whenever the input language is allowed to achieve Turing-complete power, input validation becomes undecidable; such situations should be avoided. For example, checking 'benignness' of arbitrary Javascript or even an HTML5+CSS page is a losing proposition.",
            "title": "Ad-hoc notions of input validity"
        },
        {
            "location": "/design/#parser-differentials",
            "text": "Mutual misinterpretation between system components. Verifiable composition is impossible without the means of establishing parsing equivalence between different components of a distributed system. Different interpretation of messages or data streams by components breaks any assumptions that components adhere to a shared specification and so introduces inconsistent state and unanticipated computation [@DBLP:conf/secdev/MomotBHP16]. In addition, it breaks any security schemes in which equivalent parsing of messages is a formal requirement, such as the contents of a certificate or of a signed message being interpreted identically, for example a X.509 Certificate Signing Request as seen by a Certificate Authority vs. the signed certificates as seen by the clients or signed app package contents as seen by the signature verifier versus the same content as seen by the installer (as in the recent Android Master Key bug [@freeman2013exploit]). An input language specification stronger than deterministic context-free makes the problem of establishing parser equivalence undecidable. Such input languages and systems whose trustworthiness is predicated on the component parser equivalence should be avoided. Logical programming using Prolog for instance, or languages like Scheme derived from LISP, or OCaml or Erlang would match then our requirements, but they aren't as usable as desired. As a partial solution to this problem the DECODE language parser (and all its components and eventually linked shared libraries) should be self-contained and clearly versioned and hashed and its hash verified before every computation.",
            "title": "Parser differentials"
        },
        {
            "location": "/design/#mixing-of-input-recognition-and-processing",
            "text": "Mixing of basic input validation (\"sanity checks\") and logically subsequent processing steps that belong only after the integrity of the entire message has been established makes validation hard or impossible. As a practical consequence, unanticipated reachable state exposed by such premature optimization explodes. This explosion makes principled analysis of the possible computation paths untenable. LangSec-style separation of the recognizer and processor code creates a natural partitioning that allows for simpler specification-based verification and management of code. In such designs, effective elimination of exploit-enabling implicit data flows can be achieved by simple systems memory isolation primitives.",
            "title": "Mixing of input recognition and processing"
        },
        {
            "location": "/design/#language-specification-drift",
            "text": "A common practice encouraged by rapid software development is the unconstrained addition of new features to software components and their corresponding reflection in input language specifications. Expressing complex ideas in hastily written code is a hallmark of such development practices. In essence, adding new input feature requirements to an already-underspecified input language compounds the explosion of state and computational paths.",
            "title": "Language specification drift"
        },
        {
            "location": "/design/#3-smart-rules-language",
            "text": "In light of our study of blockchain languages, use-cases and privacy by design guidelines in DECODE, this section lists three functional requirements and three usability requirements influencing the design patterns for our language.  The conclusion of this section is best described adopting once again the DSL terminology and the patterns established by Fowler. The DECODE smart-rule language is an external DSL implemented using a Syntax-Directed Translation. Its Semantic Model leads to coarse-grained tasks to be executed on the network, perhaps following a Dependency Network approach.  A tempting alternative can be that of a Production Rule System, but this way we would hide too much the internal processes in DECODE, which should be transparent and comprehensible to anyone with a beginner knowledge of programming.  An addition to this approach can be that of equipping the language with tools for constraint programming and even a context of Satisfiability Modulo Theories [@barrett2009satisfiability] to check satisfying Program Termination Proofs [@bonfante2001algorithms].",
            "title": "3. Smart-rules language"
        },
        {
            "location": "/design/#functional-requirements",
            "text": "On the basis of the design considerations made in the previous chapters, here are listed the main requirements identified for the implementation of a smart-rule language in DECODE.",
            "title": "Functional requirements"
        },
        {
            "location": "/design/#deterministic",
            "text": "This is an important feature common to all blockchain language implementations in use: that the language limits its operations to access only a fully deterministic environment. This means that, in any possible moment in time, any node can join the network and start computing contracts leading to results that are verifiable and confirmed by other nodes.  In other words, the environment accessed by the language is available to all nodes, there aren't variables that are \"private\" to a single node and may change the result by a change of their value.  The deterministic trait must be common also to the DECODE blockchain language for smart-rules, since it verifies a basic and necessary condition for blockchain based computing: that other nodes can verify and sign the results, reproducing them in their own execution environment. The computation leads to the same results that can be determined in different conditions, because all nodes have access to the same information necessary to the computation.",
            "title": "Deterministic"
        },
        {
            "location": "/design/#trustless",
            "text": "We define as trustless a language (also known as untrusted language) that allows the virtual machine to fence its execution, as in a \"sandbox\" or isolated execution environment, blocking access to unauthorised parts of the system.  A language that can be run on a \"permissionless\" (public) blockchain is a language that can be interpreted by any node. In any moment a new node may claim the capacity to do so. This means that its parser, semantics and actions on the system must be designed to handle unknowns: any deviance and malevolent code should not affect the system.",
            "title": "Trustless"
        },
        {
            "location": "/design/#solid",
            "text": "The language and the semantic model adopted by DECODE need to be capable of sandboxing untrusted code and providing security partitioning. Any process of execution should be strictly limited in what it can do. Any function or data passed to a node cannot break the sandbox in ways the participants did not intend.  For sensitive data structures, the use of proxy objects must be adopted as a security guard, only allowing the sandbox to call pre-approved methods and access pre-approved data.",
            "title": "Solid"
        },
        {
            "location": "/design/#usability-requirements",
            "text": "Here are listed the requirements emerging from an analysis of priorities about the human-machine interaction scenarios emerging from DECODE.",
            "title": "Usability requirements"
        },
        {
            "location": "/design/#simple-graphical-representation",
            "text": "A visual programming environment (VPE) facilitates participants to directly re-configure the rules governing their data: this is highly desirable in DECODE, where such code must be transparent and understandable. The event-based blocks graphical metaphor seems the most desirable for the sort of processing in DECODE: it involves letting participants manipulate a series of graphical elements (blocks) that snap onto one another and that execute sequential programs.",
            "title": "Simple, graphical representation"
        },
        {
            "location": "/design/#test-environment",
            "text": "A reliable test environment is a fundamental component for a language deployed in mission critical situations, but also for a language dealing with the distribution of its computation and wide adoption by communities of developers in different fields. Languages that improve the developer's experience when writing and testing code directly impact the quality of the code produced.  For DECODE's language implementation it is necessary to have a testing environment designed into it and from the start to facilitate its growth at the same pace of the language itself. Also, a more advanced framework for testing that goes beyond the simple usage of asserts is desirable: while being very ambitious, the implementation of solid proof of termination mechanisms that are internal to the language should be contemplated on the long term.",
            "title": "Test environment"
        },
        {
            "location": "/design/#first-class-data",
            "text": "This is a long-term requirement that should take into consideration the trade-off between feasibility, security and convenience. A data type is considered first-class in a programming language if instances of that type can be   the value of a variable  a member of an aggregate (array, list, etc.)  an argument (input) to a procedure  the value returned by a procedure  used without having a name (being the value of a variable)   For example, numbers are first-class in every language. Text strings are first-class in many languages, but not in C, in which the relevant first-class type is \u201cpointer to a character\u201d.  In DECODE it is desirable to establish data structures containing attributes and entitlements as first-class data to be seamlessly processed by the language.",
            "title": "First-class data"
        },
        {
            "location": "/design/#conclusion",
            "text": "This document is a very dense representation of language patterns and requirements to be adopted while implementing DECODE's language. Its feasibility has been verified with an extensive survey on available tools that can be used to implement this execution engine and are compatible with the DECODE licensing model.  This conclusion provides a brief list of components that can be used.",
            "title": "Conclusion"
        },
        {
            "location": "/design/#syntax-directed-translation",
            "text": "Lua is an interpreted, cross-platform, embeddable, performant and low-footprint language. Lua's popularity is on the rise in the last couple of years [@costin2017lua]. Simple design and efficient usage of resources combined with its performance make it attractive for production web applications, even to big organizations such as Wikipedia, CloudFlare and GitHub. In addition to this, Lua is one of the preferred choices for programming embedded and IoT devices. This context allows an assumption of a large and growing Lua codebase yet to be assessed. This growing Lua codebase could be potentially driving production servers and an extremely large number of devices, some perhaps with mission-critical function for example in automotive or home-automation domains.  Lua stability has been extensively tested through a number of public applications including the adoption by the gaming industry for untrusted language processing in \"World of Warcraft\" scripting. It is ideal for implementing an external DSL using C or Python as a host language.  Lua is also tooled with a working VPE implementation for code visualisation in BLOCKS, allowing the project to jump-start into an early phase of prototyping DECODE smart-rules in a visual way and directly involving pilot participants.",
            "title": "Syntax-Directed Translation"
        },
        {
            "location": "/design/#satisfiability-modulo-theories",
            "text": "Satisfiability Modulo theories (SMT) is an area of automated deduction that studies methods for checking the satisfiability of first-order formulas with respect to some logical theory of interest [@barrett2009satisfiability]. It differs from general automated deduction in that the background theory need not be finitely or even first-order axiomatizable, and specialized inference methods are used for each theory. By being theory-specific and restricting their language to certain classes of formulas (such as, typically but not exclusively, quantifier-free formulas), these specialized methods can be implemented in solvers that are more efficient in practice than general-purpose theorem provers.  While SMT techniques have been traditionally used to support deductive software verification, they are now finding applications in other areas of computer science such as planning, model checking and automated test generation. Typical theories of interest in these applications include formalizations of arithmetic, arrays, bit vectors, algebraic datatypes, equality with uninterpreted functions, and various combinations of these.   Constraint-satisfaction is crucial to software and hardware verification and static program analsysis [@de2011satisfiability] among the other possible applications.  DECODE will benefit from including SMT capabilities into the design at an early stage: even if not immediately exploited, their inclusion will keep the horizons for language development open while permitting its application in mission critical roles. The best implementation to start from in this experimentation seems to be the free and open source software \"Yices SMT Solver\" published by the Computer Science Laboratory of the Stanford Research Institute (SRI International).",
            "title": "Satisfiability Modulo theories"
        },
        {
            "location": "/api/",
            "text": "Crypto API\n\n\nHere a summary of calls available. This API is subject to change and more functions will be added according to requirements for the implementation of attribute based cryptographi in DECODE.\n\n\nCompression functions\n\n\nblz(str)\n    compress string str (BriefLZ algorithm)\n    return the compressed string or (nil, error message)\n\nunblz(cstr)\n    uncompress string cstr\n    return the uncompressed string or (nil, error message)\n\nlzf(str)\n    compress string str (LZF algorithm)\n    return the compressed string or (nil, error message)\n\nunlzf(cstr)\n    uncompress string cstr\n    return the uncompressed string or (nil, error message)\n\n\n\n\nEncoding functions\n\n\nb64encode(str [, n])\n    base64 encode string str. n is an optional integer\n    if n > 0, a newline is inserted every n character in the encoded string\n    if n == 0, no newline is inserted.\n    if not provided, n defaults to 72.\n    return the encoded string\n\nb64decode(bstr)\n    decode base64-encoded string bstr. Even non well-formed encoded strings (ie.\n    strings with no \"=\" padding) are decoded.\n    all whitespace characters in bstr are ignored.\n    return the encoded string or nil if the string cannot be decoded\n\nb58encode(str)\n    base58 encode string str\n    this uses the same alphabet as bitcoin addresses:\n    \"123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz\"\n    contrary to base64, base58 encodes a string as a long number \n    written in base58. \n    Base58 is not intended to be used for long strings, \n    if #str > 256, str is not encoded and the function raises an error.\n    No newline is inserted in the encoded string.\n    return the encoded string.\n\nb58decode(bstr)\n    decode base58-encoded string bstr\n    return the decoded string or (nil, error message) in case of an \n    invalid base58 string or if the decoded string is longer than\n    256 bytes.\n\nxor(str, key)\n    return the byte-to-byte xor of string str with string key.\n    the returned string is always the same length as str.\n    if key is longer than str, extra key bytes are ignored.\n    if key is shorter than str, it is repeated as much as necessary.\n\n\n\n\nAuthenticated encryption functions (Norx encryption algorithm)\n\n\naead_encrypt(encrypt(k, n, m [, ninc [, aad [, zad]]]) return c\n    k: key string (32 bytes)\n    n: nonce string (32 bytes)\n    m: message (plain text) string \n    ninc: optional nonce increment (useful when encrypting a long message\n         as a sequence of block). The same parameter n can be used for \n         the sequence. ninc is added to n for each block, so the actual\n         nonce used for each block encryption is distinct.\n         ninc defaults to 0 (the nonce n is used as-is)\n    aad: prefix additional data (AD) (not encrypted, prepended to the \n         encrypted message). default to the empty string\n    zad: suffix additional data (not encrypted, appended to the \n         encrypted message). default to the empty string\n    return encrypted text string c with aad prefix and zad suffix\n    (c includes the 32-byte MAC, so #c = #aad + #m + 32 + #zad)\n\naead_decrypt(k, n, c [, ninc [, aadln [, zadln]]]) \n        return (m, aad, zad) | (nil, msg)\n    k: key string (32 bytes)\n    n: nonce string (32 bytes)\n    c: encrypted message string \n    ninc: optional nonce increment (see above. defaults to 0)\n    aadln: length of the AD prefix (default to 0)\n    zadln: length of the AD suffix  (default to 0)\n    return (plain text, aad, zad) or (nil, errmsg) if MAC is not valid\n\n\n\n\nCurve25519-based key exchange\n\n\npublic_key(sk) => pk\n    return the public key associated to a curve25519 secret key\n    sk is the secret key as a 32-byte string\n    pk is the associated public key as a 32-byte string\n\nkeypair() => pk, sk\n    generates a pair of curve25519 keys (public key, secret key)\n    pk is the public key as a 32-byte string\n    sk is the secret key as a 32-byte string\n\n    Note: This is a convenience function:\n        pk, sk = keypair()  --is equivalent to\n        sk = randombytes(32); pk = public_key(sk)\n\nkey_exchange(sk, pk) => k\n    DH key exchange. Return a session key k used to encrypt \n    or decrypt a text.\n    sk is the secret key of the party invoking the function \n    (\"our secret key\"). \n    pk is the public key of the other party \n    (\"their public key\").\n    sk, pk and k are 32-byte strings\n\n\n\n\nBlake2b cryptographic hash\n\n\nblake2b_init([digest_size [, key]]) => ctx\n    initialize and return a blake2b context object\n    digest_size is the optional length of the expected digest. If provided,\n    it must be an integer between 1 and 64. It defaults to 64.\n    key is an optional key allowing to use blake2b as a MAC function.\n    If provided, key is a string with a length that must be between \n    1 and 64. The default is no key.\n    ctx is a pointer to the blake2b context as a light userdata.\n\nblake2b_update(ctx, text_fragment)\n    update the hash with a new text fragment\n    ctx is a pointer to a blake2b context as a light userdata.\n\nblake2b_final(ctx) => digest\n    return the final value of the hash\n    ctx is a pointer to a blake2b context as a light userdata.\n    The digest is returned as a string. The length of the digest\n    has been defined at the context creation (see blake2b_init()).\n    It defaults to 64.\n\nblake2b(text) => digest\n    compute the hash of a string. \n    Returns a 64-byte digest.\n    This is a convenience function which combines the init(), \n    update() and final() functions above.\n\n\n\n\nEd25519 signature\n\n\nsign_public_key(sk) => pk\n    return the public key associated to a secret key\n    sk is the secret key as a 32-byte string\n    pk is the associated public key as a 32-byte string\n\nsign_keypair() => pk, sk\n    generates a pair of ed25519 signature keys (public key, secret key)\n    pk is the public signature key as a 32-byte string\n    sk is the secret signature key as a 32-byte string\n\n    Note: This is a convenience function:\n        pk, sk = sign_keypair()     --is equivalent to\n        sk = randombytes(32); pk = sign_public_key(sk)\n\nsign(sk, text) => sig\n    sign a text with a secret key\n    sk is the secret key as a 32-byte string\n    text is the text to sign as a string\n    Return the text signature as a 64-byte string.\n\ncheck(sig, pk, text) => is_valid\n    check a text signature with a public key\n    sig is the signature to verify, as a 64-byte string\n    pk is the public key as a 32-byte string\n    text is the signed text\n    Return a boolean indicating if the signature is valid or not.\n\n    Note: curve25519 key pairs (generated with keypair())\n    cannot be used for ed25519 signature. The signature key pairs \n    must be generated with sign_keypair().\n\n\n\n\nArgon2i password derivation\n\n\nargon2i(pw, salt, nkb, niter) => k\n    compute a key given a password and some salt\n    This is a password key derivation function similar to scrypt.\n    It is intended to make derivation expensive in both CPU and memory.\n    pw: the password string\n    salt: some entropy as a string (typically 16 bytes)\n    nkb:  number of kilobytes used in RAM (as large as possible)\n    niter: number of iterations (as large as possible, >= 10)\n    Return k, a key string (32 bytes).\n\n    For example: on a CPU i5 M430 @ 2.27 GHz laptop,\n    with nkb=100000 (100MB) and niter=10, the derivation takes ~ 1.8 sec\n\n    Note: this implementation has no threading support, so no parallel \n    execution.\n\n\n\n\nLegacy cryptographic functions\n\n\nrc4raw(str, key) => encrypted (or decrypted) string\n    encrypt (or decrypt, as rc4 is symmetric) string str with string key\n    key length must be 16 (or an error is raised)\n    return the encrypted string\n    see http://en.wikipedia.org/wiki/RC4 for raw rc4 weaknesses\n    rc4(), a rc4-drop implementation, should be used instead for most uses\n\nrc4(str, key) => encrypted (or decrypted) string\n    this is a rc4-drop encryption function with a 256-byte drop\n    (ie. the rc4 state is initialized by \"encrypting\" a 256-byte block of\n    zero bytes before starting the encyption of the string)\n    arguments and return are the same as rc4raw()\n    key length must be 16 (or an error is raised)\n\nmd5(str) => digest\n    return the md5 hash of string str as a 16-byte binary string\n    (no hex encoding)\n\n\n\n\nMisc functions\n\n\nrandombytes(n)\n    return a random string of length n generated by the OS RNG \n    (/dev/urandom on Linux, or CryptGenRandom() on Windows)",
            "title": "API"
        },
        {
            "location": "/api/#crypto-api",
            "text": "Here a summary of calls available. This API is subject to change and more functions will be added according to requirements for the implementation of attribute based cryptographi in DECODE.",
            "title": "Crypto API"
        },
        {
            "location": "/api/#compression-functions",
            "text": "blz(str)\n    compress string str (BriefLZ algorithm)\n    return the compressed string or (nil, error message)\n\nunblz(cstr)\n    uncompress string cstr\n    return the uncompressed string or (nil, error message)\n\nlzf(str)\n    compress string str (LZF algorithm)\n    return the compressed string or (nil, error message)\n\nunlzf(cstr)\n    uncompress string cstr\n    return the uncompressed string or (nil, error message)",
            "title": "Compression functions"
        },
        {
            "location": "/api/#encoding-functions",
            "text": "b64encode(str [, n])\n    base64 encode string str. n is an optional integer\n    if n > 0, a newline is inserted every n character in the encoded string\n    if n == 0, no newline is inserted.\n    if not provided, n defaults to 72.\n    return the encoded string\n\nb64decode(bstr)\n    decode base64-encoded string bstr. Even non well-formed encoded strings (ie.\n    strings with no \"=\" padding) are decoded.\n    all whitespace characters in bstr are ignored.\n    return the encoded string or nil if the string cannot be decoded\n\nb58encode(str)\n    base58 encode string str\n    this uses the same alphabet as bitcoin addresses:\n    \"123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz\"\n    contrary to base64, base58 encodes a string as a long number \n    written in base58. \n    Base58 is not intended to be used for long strings, \n    if #str > 256, str is not encoded and the function raises an error.\n    No newline is inserted in the encoded string.\n    return the encoded string.\n\nb58decode(bstr)\n    decode base58-encoded string bstr\n    return the decoded string or (nil, error message) in case of an \n    invalid base58 string or if the decoded string is longer than\n    256 bytes.\n\nxor(str, key)\n    return the byte-to-byte xor of string str with string key.\n    the returned string is always the same length as str.\n    if key is longer than str, extra key bytes are ignored.\n    if key is shorter than str, it is repeated as much as necessary.",
            "title": "Encoding functions"
        },
        {
            "location": "/api/#authenticated-encryption-functions-norx-encryption-algorithm",
            "text": "aead_encrypt(encrypt(k, n, m [, ninc [, aad [, zad]]]) return c\n    k: key string (32 bytes)\n    n: nonce string (32 bytes)\n    m: message (plain text) string \n    ninc: optional nonce increment (useful when encrypting a long message\n         as a sequence of block). The same parameter n can be used for \n         the sequence. ninc is added to n for each block, so the actual\n         nonce used for each block encryption is distinct.\n         ninc defaults to 0 (the nonce n is used as-is)\n    aad: prefix additional data (AD) (not encrypted, prepended to the \n         encrypted message). default to the empty string\n    zad: suffix additional data (not encrypted, appended to the \n         encrypted message). default to the empty string\n    return encrypted text string c with aad prefix and zad suffix\n    (c includes the 32-byte MAC, so #c = #aad + #m + 32 + #zad)\n\naead_decrypt(k, n, c [, ninc [, aadln [, zadln]]]) \n        return (m, aad, zad) | (nil, msg)\n    k: key string (32 bytes)\n    n: nonce string (32 bytes)\n    c: encrypted message string \n    ninc: optional nonce increment (see above. defaults to 0)\n    aadln: length of the AD prefix (default to 0)\n    zadln: length of the AD suffix  (default to 0)\n    return (plain text, aad, zad) or (nil, errmsg) if MAC is not valid",
            "title": "Authenticated encryption functions (Norx encryption algorithm)"
        },
        {
            "location": "/api/#curve25519-based-key-exchange",
            "text": "public_key(sk) => pk\n    return the public key associated to a curve25519 secret key\n    sk is the secret key as a 32-byte string\n    pk is the associated public key as a 32-byte string\n\nkeypair() => pk, sk\n    generates a pair of curve25519 keys (public key, secret key)\n    pk is the public key as a 32-byte string\n    sk is the secret key as a 32-byte string\n\n    Note: This is a convenience function:\n        pk, sk = keypair()  --is equivalent to\n        sk = randombytes(32); pk = public_key(sk)\n\nkey_exchange(sk, pk) => k\n    DH key exchange. Return a session key k used to encrypt \n    or decrypt a text.\n    sk is the secret key of the party invoking the function \n    (\"our secret key\"). \n    pk is the public key of the other party \n    (\"their public key\").\n    sk, pk and k are 32-byte strings",
            "title": "Curve25519-based key exchange"
        },
        {
            "location": "/api/#blake2b-cryptographic-hash",
            "text": "blake2b_init([digest_size [, key]]) => ctx\n    initialize and return a blake2b context object\n    digest_size is the optional length of the expected digest. If provided,\n    it must be an integer between 1 and 64. It defaults to 64.\n    key is an optional key allowing to use blake2b as a MAC function.\n    If provided, key is a string with a length that must be between \n    1 and 64. The default is no key.\n    ctx is a pointer to the blake2b context as a light userdata.\n\nblake2b_update(ctx, text_fragment)\n    update the hash with a new text fragment\n    ctx is a pointer to a blake2b context as a light userdata.\n\nblake2b_final(ctx) => digest\n    return the final value of the hash\n    ctx is a pointer to a blake2b context as a light userdata.\n    The digest is returned as a string. The length of the digest\n    has been defined at the context creation (see blake2b_init()).\n    It defaults to 64.\n\nblake2b(text) => digest\n    compute the hash of a string. \n    Returns a 64-byte digest.\n    This is a convenience function which combines the init(), \n    update() and final() functions above.",
            "title": "Blake2b cryptographic hash"
        },
        {
            "location": "/api/#ed25519-signature",
            "text": "sign_public_key(sk) => pk\n    return the public key associated to a secret key\n    sk is the secret key as a 32-byte string\n    pk is the associated public key as a 32-byte string\n\nsign_keypair() => pk, sk\n    generates a pair of ed25519 signature keys (public key, secret key)\n    pk is the public signature key as a 32-byte string\n    sk is the secret signature key as a 32-byte string\n\n    Note: This is a convenience function:\n        pk, sk = sign_keypair()     --is equivalent to\n        sk = randombytes(32); pk = sign_public_key(sk)\n\nsign(sk, text) => sig\n    sign a text with a secret key\n    sk is the secret key as a 32-byte string\n    text is the text to sign as a string\n    Return the text signature as a 64-byte string.\n\ncheck(sig, pk, text) => is_valid\n    check a text signature with a public key\n    sig is the signature to verify, as a 64-byte string\n    pk is the public key as a 32-byte string\n    text is the signed text\n    Return a boolean indicating if the signature is valid or not.\n\n    Note: curve25519 key pairs (generated with keypair())\n    cannot be used for ed25519 signature. The signature key pairs \n    must be generated with sign_keypair().",
            "title": "Ed25519 signature"
        },
        {
            "location": "/api/#argon2i-password-derivation",
            "text": "argon2i(pw, salt, nkb, niter) => k\n    compute a key given a password and some salt\n    This is a password key derivation function similar to scrypt.\n    It is intended to make derivation expensive in both CPU and memory.\n    pw: the password string\n    salt: some entropy as a string (typically 16 bytes)\n    nkb:  number of kilobytes used in RAM (as large as possible)\n    niter: number of iterations (as large as possible, >= 10)\n    Return k, a key string (32 bytes).\n\n    For example: on a CPU i5 M430 @ 2.27 GHz laptop,\n    with nkb=100000 (100MB) and niter=10, the derivation takes ~ 1.8 sec\n\n    Note: this implementation has no threading support, so no parallel \n    execution.",
            "title": "Argon2i password derivation"
        },
        {
            "location": "/api/#legacy-cryptographic-functions",
            "text": "rc4raw(str, key) => encrypted (or decrypted) string\n    encrypt (or decrypt, as rc4 is symmetric) string str with string key\n    key length must be 16 (or an error is raised)\n    return the encrypted string\n    see http://en.wikipedia.org/wiki/RC4 for raw rc4 weaknesses\n    rc4(), a rc4-drop implementation, should be used instead for most uses\n\nrc4(str, key) => encrypted (or decrypted) string\n    this is a rc4-drop encryption function with a 256-byte drop\n    (ie. the rc4 state is initialized by \"encrypting\" a 256-byte block of\n    zero bytes before starting the encyption of the string)\n    arguments and return are the same as rc4raw()\n    key length must be 16 (or an error is raised)\n\nmd5(str) => digest\n    return the md5 hash of string str as a 16-byte binary string\n    (no hex encoding)",
            "title": "Legacy cryptographic functions"
        },
        {
            "location": "/api/#misc-functions",
            "text": "randombytes(n)\n    return a random string of length n generated by the OS RNG \n    (/dev/urandom on Linux, or CryptGenRandom() on Windows)",
            "title": "Misc functions"
        }
    ]
}